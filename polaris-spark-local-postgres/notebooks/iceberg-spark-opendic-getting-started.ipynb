{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335f8e68",
   "metadata": {},
   "source": [
    "## OpenDict DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be599f01",
   "metadata": {},
   "source": [
    "### 1. Install client libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513a3c48-995c-4060-9d61-2a499be0a0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark-opendic==0.4.0 in /usr/local/lib/python3.10/site-packages (0.4)\n",
      "Requirement already satisfied: pydantic>=2.10.6 in /usr/local/lib/python3.10/site-packages (from pyspark-opendic==0.4.0) (2.11.5)\n",
      "Requirement already satisfied: pytest-cov>=6.1.1 in /usr/local/lib/python3.10/site-packages (from pyspark-opendic==0.4.0) (6.1.1)\n",
      "Requirement already satisfied: pyspark>=3.5.5 in /opt/spark/python (from pyspark-opendic==0.4.0) (3.5.5)\n",
      "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.10/site-packages (from pyspark-opendic==0.4.0) (2.32.3)\n",
      "Requirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.10/site-packages (from pyspark-opendic==0.4.0) (2.2.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=2.2.3->pyspark-opendic==0.4.0) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/site-packages (from pandas>=2.2.3->pyspark-opendic==0.4.0) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=2.2.3->pyspark-opendic==0.4.0) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=2.2.3->pyspark-opendic==0.4.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.10.6->pyspark-opendic==0.4.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.10.6->pyspark-opendic==0.4.0) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.10.6->pyspark-opendic==0.4.0) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.10.6->pyspark-opendic==0.4.0) (4.12.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/site-packages (from pyspark>=3.5.5->pyspark-opendic==0.4.0) (0.10.9.7)\n",
      "Requirement already satisfied: pytest>=4.6 in /usr/local/lib/python3.10/site-packages (from pytest-cov>=6.1.1->pyspark-opendic==0.4.0) (8.4.0)\n",
      "Requirement already satisfied: coverage[toml]>=7.5 in /usr/local/lib/python3.10/site-packages (from pytest-cov>=6.1.1->pyspark-opendic==0.4.0) (7.8.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.3->pyspark-opendic==0.4.0) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.3->pyspark-opendic==0.4.0) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.3->pyspark-opendic==0.4.0) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.3->pyspark-opendic==0.4.0) (2025.1.31)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.10/site-packages (from coverage[toml]>=7.5->pytest-cov>=6.1.1->pyspark-opendic==0.4.0) (2.2.1)\n",
      "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.10/site-packages (from pytest>=4.6->pytest-cov>=6.1.1->pyspark-opendic==0.4.0) (2.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1 in /usr/local/lib/python3.10/site-packages (from pytest>=4.6->pytest-cov>=6.1.1->pyspark-opendic==0.4.0) (1.2.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/site-packages (from pytest>=4.6->pytest-cov>=6.1.1->pyspark-opendic==0.4.0) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/site-packages (from pytest>=4.6->pytest-cov>=6.1.1->pyspark-opendic==0.4.0) (24.2)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.10/site-packages (from pytest>=4.6->pytest-cov>=6.1.1->pyspark-opendic==0.4.0) (2.19.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->pyspark-opendic==0.4.0) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: snowflake-opendic==0.1.21 in /usr/local/lib/python3.10/site-packages (0.1.21)\n",
      "Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.10/site-packages (from snowflake-opendic==0.1.21) (0.10.2)\n",
      "Requirement already satisfied: snowflake-connector-python[pandas]>=3.13.2 in /usr/local/lib/python3.10/site-packages (from snowflake-opendic==0.1.21) (3.15.0)\n",
      "Requirement already satisfied: pydantic>=2.11.3 in /usr/local/lib/python3.10/site-packages (from snowflake-opendic==0.1.21) (2.11.5)\n",
      "Requirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.10/site-packages (from snowflake-opendic==0.1.21) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/site-packages (from pandas>=2.2.3->snowflake-opendic==0.1.21) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=2.2.3->snowflake-opendic==0.1.21) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=2.2.3->snowflake-opendic==0.1.21) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=2.2.3->snowflake-opendic==0.1.21) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.11.3->snowflake-opendic==0.1.21) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.11.3->snowflake-opendic==0.1.21) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.11.3->snowflake-opendic==0.1.21) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.11.3->snowflake-opendic==0.1.21) (0.7.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (3.18.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (3.10)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (4.3.6)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (1.5.1)\n",
      "Requirement already satisfied: botocore>=1.24 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (1.38.33)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (45.0.4)\n",
      "Requirement already satisfied: tomlkit in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (0.13.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (3.4.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (2.4.0)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (25.1.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (2.10.1)\n",
      "Requirement already satisfied: boto3>=1.24 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (1.38.33)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (2025.1.31)\n",
      "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (2.32.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (24.2)\n",
      "Requirement already satisfied: pyarrow<19.0.0 in /usr/local/lib/python3.10/site-packages (from snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (17.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/site-packages (from boto3>=1.24->snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.10/site-packages (from boto3>=1.24->snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (0.13.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/site-packages (from botocore>=1.24->snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (2.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]>=3.13.2->snowflake-opendic==0.1.21) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->snowflake-opendic==0.1.21) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark-opendic==0.4.0\n",
    "%pip install snowflake-opendic==0.1.21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f5563-2335-4b03-9283-0ed534b8afb2",
   "metadata": {},
   "source": [
    "### 2 Configure spark-iceberg session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0f90e-1366-4bf6-a321-6dec01edba40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.1 read_secret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510348f2-c283-4782-b33f-fc3b6c01719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession  # type: ignore\n",
    "\n",
    "def read_secret(secret_name):\n",
    "    \"\"\" Get `secret_name` from docker-compose secret store\"\"\"\n",
    "    secret_path = f\"/run/secrets/{secret_name}\"\n",
    "    try:\n",
    "        with open(secret_path, \"r\") as f:\n",
    "            return f.read().strip()  # Remove any trailing newline\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Secret {secret_name} not found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c09faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9469d74d-1eb9-4126-acfc-44873cb26ef7",
   "metadata": {},
   "source": [
    "#### 2.2 Define session variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9308bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_NAME = 'AZURE_CATALOG'\n",
    "ENGINEER_CLIENT_ID = read_secret(\"engineer_client_id\")\n",
    "ENGINEER_CLIENT_SECRET =  read_secret(\"engineer_client_secret\")\n",
    "ADLS_IO=\"org.apache.iceberg.azure.adlsv2.ADLSFileIO\"\n",
    "CATALOG_URI=\"https://opendict.duckdns.org/api/catalog\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592c90e",
   "metadata": {},
   "source": [
    "#### 2.3 Configure spark session with variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8961c31e-19e6-4470-bbae-4611bf76f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/11 09:29:23 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://80e51181c7c0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff7b02a0e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_session(client_id, client_secret, scope, fileio_impl):\n",
    "    spark = (SparkSession.builder\n",
    "        .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.0,software.amazon.awssdk:bundle:2.28.17,software.amazon.awssdk:url-connection-client:2.28.17\")\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\")\n",
    "        .config(\"spark.sql.catalog.polaris\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "        .config(\"spark.sql.catalog.polaris.type\", \"rest\")\n",
    "        .config(\"spark.sql.catalog.polaris.warehouse\", CATALOG_NAME)\n",
    "        .config(\"spark.sql.catalog.polaris.uri\", CATALOG_URI)\n",
    "        .config(\"spark.sql.catalog.polaris.credential\", f\"{client_id}:{client_secret}\")\n",
    "        .config(\"spark.sql.catalog.polaris.scope\", scope)\n",
    "        .config(\"spark.sql.catalog.my_iceberg.auth.type\", \"OAUTH2\")\n",
    "        .config(\"spark.sql.defaultCatalog\", \"polaris\")\n",
    "        .config(\"oauth2-server-uri\",\"https://opendict.duckdns.org/api/catalog/v1/oauth/tokens\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\")\n",
    "        .config(\"spark.sql.catalog.polaris.token-refresh-enabled\", \"true\")\n",
    "        .config(\"spark.sql.catalog.polaris.header.X-Iceberg-Access-Delegation\", 'vended-credentials')\n",
    "        .config(\"spark.sql.catalog.polaris.io-impl\", fileio_impl)\n",
    "        .config(\"spark.history.fs.logDirectory\", \"/home/iceberg/spark-events\")).getOrCreate()\n",
    "        \n",
    "    print(\"Spark Running\")\n",
    "    return spark\n",
    "\n",
    "\n",
    "## Start Spark Session\n",
    "spark = create_session(client_id=ENGINEER_CLIENT_ID, client_secret=ENGINEER_CLIENT_SECRET, scope='PRINCIPAL_ROLE:ALL',fileio_impl=ADLS_IO )\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbcf250",
   "metadata": {},
   "source": [
    "#### 2.4 Wrap spark session with the opendict-spark library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ccb2cb-8448-4111-b2af-bd3b19b92835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog initialized\n"
     ]
    }
   ],
   "source": [
    "from pyspark_opendic.catalog import OpenDicCatalog  # type: ignore\n",
    "\n",
    "# Init opendict client library\n",
    "API_URI= \"https://opendict.duckdns.org/api\"\n",
    "catalog = OpenDicCatalog(spark, API_URI)\n",
    "print(\"Catalog initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f7adc-e72e-4ae7-b436-4a3f1c7b8e57",
   "metadata": {},
   "source": [
    "### 3. Configure up opendict-snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1adddea-72df-4642-a114-c64ab0fddbca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secrets read ✔️\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/snowflake_opendic/snow_opendic.py:51: RuntimeWarning: Config file must be in TOML format\n",
      "  warnings.warn(\"Config file must be in TOML format\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake conn initialized ✔️\n",
      "Connection Established | Server: America/Los_Angeles | Latency: 0.233425 ✔︎\n",
      "Catalog initialized ✔️\n"
     ]
    }
   ],
   "source": [
    "from snowflake_opendic.snow_opendic import snowflake_connect # type: ignore\n",
    "\n",
    "def read_secret(secret_name):\n",
    "    \"\"\" Get `secret_name` from docker-compose secret store\"\"\"\n",
    "    secret_path = f\"/run/secrets/{secret_name}\"\n",
    "    try:\n",
    "        with open(secret_path, \"r\") as f:\n",
    "            return f.read().strip()  # Remove any trailing newline\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Secret {secret_name} not found.\")\n",
    "        return None\n",
    "\n",
    "def snowflake_init_db(conn):\n",
    "    with conn.cursor() as curr:\n",
    "        curr.execute(\"CREATE DATABASE IF NOT EXISTS OPENDIC;\")\n",
    "        curr.execute(\"use OPENDIC;\")\n",
    "        curr.execute(\"CREATE SCHEMA IF NOT EXISTS EXPERIMENT;\")\n",
    "\n",
    "ENGINEER_CLIENT_ID = read_secret(\"engineer_client_id\")\n",
    "ENGINEER_CLIENT_SECRET = read_secret(\"engineer_client_secret\")\n",
    "\n",
    "print(\"Secrets read ✔️\")\n",
    "\n",
    "config_path = f\"/run/secrets/snowflake-conf\"\n",
    "SNOWFLAKE_CONN = snowflake_connect(config_path)\n",
    "snowflake_init_db(SNOWFLAKE_CONN)\n",
    "\n",
    "print(\"Snowflake conn initialized ✔️\")\n",
    "\n",
    "\n",
    "from snowflake_opendic.catalog import OpenDicSnowflakeCatalog\n",
    "\n",
    "\n",
    "POLARIS_URI= \"https://opendict.duckdns.org/api\"\n",
    "\n",
    "snowflake_catalog = OpenDicSnowflakeCatalog(SNOWFLAKE_CONN, POLARIS_URI, ENGINEER_CLIENT_ID, ENGINEER_CLIENT_SECRET)\n",
    "print(\"Catalog initialized ✔️\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806fa1fb-19ac-40be-8d41-7b3dbfb06630",
   "metadata": {},
   "source": [
    "### 4. Scenario and datalake overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fccda30-924c-45ff-af72-84c9bc624198",
   "metadata": {},
   "source": [
    "#### 4.1 The AZURE DATALAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6853a0",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "warehouse/\n",
    "├── SYSTEM/\n",
    "└── nyc/taxis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30d98c61-b213-4bcd-b1ee-216dd8be9d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYSTEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nyc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace\n",
       "0    SYSTEM\n",
       "1       nyc"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SHOW NAMESPACES\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e52052-af01-4c4d-8f1a-d62c9697fc3a",
   "metadata": {},
   "source": [
    "#### 4.2 The taxis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51a85fc-15cd-4699-88ca-ac92eff04c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>usd_to_dkk(fare_amount)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-01 00:00:18</td>\n",
       "      <td>2021-04-01 00:21:54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>207.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-01 00:42:37</td>\n",
       "      <td>2021-04-01 00:46:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>40.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-01 00:57:56</td>\n",
       "      <td>2021-04-01 01:08:22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>93.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-01 00:01:58</td>\n",
       "      <td>2021-04-01 00:54:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>360.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-01 00:24:55</td>\n",
       "      <td>2021-04-01 00:34:33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>73.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-04-01 00:19:16</td>\n",
       "      <td>2021-04-01 00:21:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>36.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-04-01 00:25:11</td>\n",
       "      <td>2021-04-01 00:31:53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>93.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-04-01 00:27:53</td>\n",
       "      <td>2021-04-01 00:47:03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.90</td>\n",
       "      <td>215.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-04-01 00:24:24</td>\n",
       "      <td>2021-04-01 00:37:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>97.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-04-01 00:19:18</td>\n",
       "      <td>2021-04-01 00:41:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.90</td>\n",
       "      <td>228.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  trip_distance  usd_to_dkk(fare_amount)\n",
       "0  2021-04-01 00:00:18   2021-04-01 00:21:54              1.0           8.40                  207.825\n",
       "1  2021-04-01 00:42:37   2021-04-01 00:46:23              1.0           0.90                   40.750\n",
       "2  2021-04-01 00:57:56   2021-04-01 01:08:22              1.0           3.40                   93.725\n",
       "3  2021-04-01 00:01:58   2021-04-01 00:54:27              1.0           0.00                  360.230\n",
       "4  2021-04-01 00:24:55   2021-04-01 00:34:33              1.0           1.96                   73.350\n",
       "5  2021-04-01 00:19:16   2021-04-01 00:21:46              1.0           0.77                   36.675\n",
       "6  2021-04-01 00:25:11   2021-04-01 00:31:53              1.0           3.65                   93.725\n",
       "7  2021-04-01 00:27:53   2021-04-01 00:47:03              0.0           8.90                  215.975\n",
       "8  2021-04-01 00:24:24   2021-04-01 00:37:50              1.0           2.98                   97.800\n",
       "9  2021-04-01 00:19:18   2021-04-01 00:41:25              1.0           8.90                  228.200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, usd_to_dkk(fare_amount) \n",
    "          FROM nyc.taxis limit 10\n",
    "          \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1be37f-4885-4cb5-8d66-7de075c39663",
   "metadata": {},
   "source": [
    "#### 4.3 Task definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472e4d7",
   "metadata": {},
   "source": [
    "Translate fare_amount DKK and add a 25% MOMS rate.\n",
    "\n",
    "**Problem**\n",
    "- Access same table in Snowflake and Spark\n",
    "- Want to define once\n",
    "- Want updates to propogate\n",
    "\n",
    "**Solution**: \n",
    "- OpenDict user-defined object\n",
    "- Define, create, map, and sync function between multiple engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39961f6",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Code example\n",
    "CREATE FUNCTION usd_to_dkk(amount FLOAT)\n",
    "  RETURNS FLOAT\n",
    "  AS\n",
    "  $$\n",
    "    amount * 6.52 * 1.25 \n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354fa57d-4e4b-40e3-b560-afdf7abaadc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4.4. Define the schema for a OpenDict function object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99808c3e-7fef-42f6-9a1e-4e44b798c69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udoType</th>\n",
       "      <th>properties</th>\n",
       "      <th>createdTimestamp</th>\n",
       "      <th>lastUpdatedTimestamp</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function</td>\n",
       "      <td>{'args': 'STRING', 'return_type': 'STRING', 'created_time': 'STRING', 'entity_version': 'STRING', 'uname': 'STRING', 'def': 'STRING', 'last_updated_time': 'STRING', 'language': 'STRING', 'comment': 'STRING'}</td>\n",
       "      <td>1970-01-01T00:00Z</td>\n",
       "      <td>1970-01-01T00:00Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    udoType                                                                                                                                                                                                       properties   createdTimestamp lastUpdatedTimestamp version\n",
       "0  function  {'args': 'STRING', 'return_type': 'STRING', 'created_time': 'STRING', 'entity_version': 'STRING', 'uname': 'STRING', 'def': 'STRING', 'last_updated_time': 'STRING', 'language': 'STRING', 'comment': 'STRING'}  1970-01-01T00:00Z    1970-01-01T00:00Z    None"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    DEFINE OPEN function\n",
    "    props {\n",
    "        \"args\": \"map\",\n",
    "        \"language\": \"string\",\n",
    "        \"def\": \"string\",\n",
    "        \"comment\": \"string\",\n",
    "        \"return_type\": \"string\"\n",
    "    }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a117eb1-0929-4e30-9dea-c6980411f991",
   "metadata": {},
   "source": [
    "#### 4.5. Create a new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59b83c05-2e49-449c-9fc3-f644acf682c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type-name</th>\n",
       "      <th>object-name</th>\n",
       "      <th>props</th>\n",
       "      <th>created-time-stamp</th>\n",
       "      <th>last-updated-time-stamp</th>\n",
       "      <th>entity-version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function</td>\n",
       "      <td>usd_to_dkk</td>\n",
       "      <td>{'args': {'amount': 'DOUBLE'}, 'return_type': 'DOUBLE', 'language': 'SQL', 'comment': 'Conversion function for USD to DKK including VAT', 'def': 'amount * 6.52 * 1.25'}</td>\n",
       "      <td>2025-06-11T00:44:24.368587804Z</td>\n",
       "      <td>2025-06-11T00:44:24.368588964Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type-name object-name                                                                                                                                                                     props              created-time-stamp         last-updated-time-stamp  entity-version\n",
       "0  function  usd_to_dkk  {'args': {'amount': 'DOUBLE'}, 'return_type': 'DOUBLE', 'language': 'SQL', 'comment': 'Conversion function for USD to DKK including VAT', 'def': 'amount * 6.52 * 1.25'}  2025-06-11T00:44:24.368587804Z  2025-06-11T00:44:24.368588964Z               1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    " \"\"\"\n",
    " CREATE OPEN function usd_to_dkk\n",
    "    PROPS {\n",
    "            \"args\": {\n",
    "                \"amount\": \"DOUBLE\"\n",
    "                },\n",
    "            \"language\": \"SQL\",\n",
    "            \"def\": \"amount * 6.52 * 1.25\",\n",
    "            \"comment\": \"Conversion function for USD to DKK including VAT\",\n",
    "            \"return_type\": \"DOUBLE\"\n",
    "        }\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4ce21-1ded-4e92-8b3a-18f3d2264aa7",
   "metadata": {},
   "source": [
    "#### 4.6. Create Mappings for spark and snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "260d1569-26c2-4a6b-98fd-184eb8ba5aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typeName</th>\n",
       "      <th>platformName</th>\n",
       "      <th>syntax</th>\n",
       "      <th>objectDumpMap</th>\n",
       "      <th>createdTimestamp</th>\n",
       "      <th>lastUpdatedTimestamp</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function</td>\n",
       "      <td>spark</td>\n",
       "      <td>CREATE &lt;type&gt; &lt;name&gt;(&lt;args&gt;)\\n    RETURNS &lt;return_type&gt;\\n    LANGUAGE &lt;language&gt;\\n    AS 'RETURN &lt;def&gt;';</td>\n",
       "      <td>{'args': {'propType': 'map', 'format': '&lt;key&gt; &lt;value&gt;', 'delimiter': ', '}}</td>\n",
       "      <td>2025-06-11T00:49:36.726836830Z</td>\n",
       "      <td>2025-06-11T00:49:36.726837190Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   typeName platformName                                                                                                    syntax                                                                objectDumpMap                createdTimestamp            lastUpdatedTimestamp  version\n",
       "0  function        spark  CREATE <type> <name>(<args>)\\n    RETURNS <return_type>\\n    LANGUAGE <language>\\n    AS 'RETURN <def>';  {'args': {'propType': 'map', 'format': '<key> <value>', 'delimiter': ', '}}  2025-06-11T00:49:36.726836830Z  2025-06-11T00:49:36.726837190Z        1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "\"\"\"\n",
    "ADD OPEN MAPPING function PLATFORM spark\n",
    "SYNTAX {\n",
    "    CREATE <type> <name>(<args>)\n",
    "    RETURNS <return_type>\n",
    "    LANGUAGE <language>\n",
    "    AS 'RETURN <def>';\n",
    "}\n",
    "PROPS {\n",
    "    \"args\": {\n",
    "            \"propType\": \"map\",\n",
    "            \"format\": \"<key> <value>\",\n",
    "            \"delimiter\": \", \"\n",
    "        }\n",
    "}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023dc59-10d0-42fe-8fa8-c9662c9b2078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typeName</th>\n",
       "      <th>platformName</th>\n",
       "      <th>syntax</th>\n",
       "      <th>objectDumpMap</th>\n",
       "      <th>createdTimestamp</th>\n",
       "      <th>lastUpdatedTimestamp</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function</td>\n",
       "      <td>snowflake</td>\n",
       "      <td>CREATE OR REPLACE &lt;type&gt; &lt;name&gt;(&lt;args&gt;)\\nRETURNS &lt;return_type&gt;\\nLANGUAGE &lt;language&gt;\\nAS \\n$$\\n&lt;def&gt;\\n$$;</td>\n",
       "      <td>{'args': {'propType': 'map', 'format': '&lt;key&gt; &lt;value&gt;', 'delimiter': ', '}}</td>\n",
       "      <td>2025-06-11T00:51:46.053997346Z</td>\n",
       "      <td>2025-06-11T00:51:46.053997746Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   typeName platformName                                                                                                    syntax                                                                objectDumpMap                createdTimestamp            lastUpdatedTimestamp  version\n",
       "0  function    snowflake  CREATE OR REPLACE <type> <name>(<args>)\\nRETURNS <return_type>\\nLANGUAGE <language>\\nAS \\n$$\\n<def>\\n$$;  {'args': {'propType': 'map', 'format': '<key> <value>', 'delimiter': ', '}}  2025-06-11T00:51:46.053997346Z  2025-06-11T00:51:46.053997746Z        1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "\"\"\"\n",
    "ADD OPEN MAPPING function PLATFORM snowflake\n",
    "SYNTAX {\n",
    "CREATE OR REPLACE <type> <name>(<args>)\n",
    "RETURNS <return_type>\n",
    "LANGUAGE <language>\n",
    "AS \n",
    "$$\n",
    "<def>\n",
    "$$;\n",
    "}\n",
    "PROPS {\n",
    "    \"args\": {\n",
    "            \"propType\": \"map\",\n",
    "            \"format\": \"<key> <value>\",\n",
    "            \"delimiter\": \", \"\n",
    "        }\n",
    "}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc56e5-ab65-4e4d-b9a4-e3926f1c047a",
   "metadata": {},
   "source": [
    "#### 4.7 Sync to engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f252c14-5da5-405c-ad0c-e9bfa8e2b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/11 09:30:34 WARN SimpleFunctionRegistry: The function usd_to_dkk replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "    \"executions\": [\n",
       "        {\n",
       "            \"sql\": \"CREATE function usd_to_dkk(amount DOUBLE)\\n    RETURNS DOUBLE\\n    LANGUAGE SQL\\n    AS 'RETURN amount * 6.52 * 1.25';\",\n",
       "            \"status\": \"function registered\"\n",
       "        }\n",
       "    ]\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "{\n",
       "    \"executions\": [\n",
       "        {\n",
       "            \"sql\": \"CREATE function usd_to_dkk(amount DOUBLE)\\n    RETURNS DOUBLE\\n    LANGUAGE SQL\\n    AS 'RETURN amount * 6.52 * 1.25';\",\n",
       "            \"status\": \"function registered\"\n",
       "        }\n",
       "    ]\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SYNC OPEN OBJECTS for spark\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56541e98-2376-4f30-a11b-f90589510f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snowflake_catalog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msnowflake_catalog\u001b[49m\u001b[38;5;241m.\u001b[39msql(\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    SYNC OPEN OBJECTS for snowflake\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snowflake_catalog' is not defined"
     ]
    }
   ],
   "source": [
    "snowflake_catalog.sql(\n",
    "    \"\"\"\n",
    "    SYNC OPEN OBJECTS for snowflake\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a35328",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b019448-2b04-4063-a812-bb598122ef04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### List objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13db8f-0e7c-4e0b-8b88-ba092fe91530",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN TYPES\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6a8bb-2989-4873-a8b4-e78416aea85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN function\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a0829-e1bc-40a4-b2e9-583369bc2785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show mapping for <object> to <platform>. Example: [Platform_mapping(function_v2 -> snowflake)]\n",
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN MAPPING function_v2 PLATFORM snowflake\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f2f0d-4042-4304-92e7-9b08b1154757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all mappings from <object>. Example: [snowflake,spark]\n",
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN PLATFORMS FOR function_v2\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ccc6c-fac8-4d6c-a9d6-a556d5a91037",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN PLATFORMS\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d02df-c4f4-46f4-b707-99d3d2869d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN MAPPINGS FOR snowflake\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2991f5-6099-4bc0-9e64-dda501c6104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SYNC OPEN function_v2 for snowflake\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18be6e2-30ca-44ae-af80-da349d61916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SYNC OPEN OBJECTS for snowflake\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13475c-abcc-4bed-96d5-0d9044aee319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Drop objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba6692-c3a3-45e8-b1a6-a7d33697a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    DROP OPEN function\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "159960df-32ec-4d43-a16a-86e32780e4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "    \"error\": \"HTTP Error\",\n",
       "    \"details\": \"404 Client Error: Not Found for url: https://opendict.duckdns.org/api/opendic/v1/platforms/snowflake\",\n",
       "    \"Catalog Response\": null\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "{\n",
       "    \"error\": \"HTTP Error\",\n",
       "    \"details\": \"404 Client Error: Not Found for url: https://opendict.duckdns.org/api/opendic/v1/platforms/snowflake\",\n",
       "    \"Catalog Response\": null\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    DROP OPEN MAPPINGS for snowflake\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "485cef78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deleted all mappings for platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Deleted all mappings for platform\n",
       "0                             spark"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    DROP OPEN MAPPINGS for spark\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f67035-aa7b-4eab-8ba0-7e7132c68106",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Visualize opendic tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66730eb2-aa42-42b5-8f15-f6fb6c3908d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "show tables in SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1708a-3517-4c09-aaad-f51d08929cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select uname as name, args, return_type, signature, runtime, language, comment, packages, def   from SYSTEM.function_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb219f-304b-47c3-91b1-6bf220580183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "USE SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365f5c0-5d66-4330-8602-f665a5ffee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from SYSTEM.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930682ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/home/iceberg/data/yellow_tripdata_2021-04.parquet\")\n",
    "df.write.saveAsTable(\"nyc.taxis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cb02b-b5ee-4a2f-be39-030671dcb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM nyc.taxis limit 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
