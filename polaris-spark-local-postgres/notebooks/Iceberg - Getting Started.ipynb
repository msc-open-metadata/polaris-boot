{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1041ae6f",
   "metadata": {},
   "source": [
    "![iceberg-logo](https://www.apache.org/logos/res/iceberg/iceberg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fb2ab",
   "metadata": {},
   "source": [
    "### [Docker, Spark, and Iceberg: The Fastest Way to Try Iceberg!](https://tabular.io/blog/docker-spark-and-iceberg/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21411ff4-eeee-476d-ac2e-b2b727a1e2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark-opendic==0.2.6\n",
      "  Downloading pyspark_opendic-0.2.6-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pydantic>=2.10.6 in /usr/local/lib/python3.10/site-packages (from pyspark-opendic==0.2.6) (2.10.6)\n",
      "Requirement already satisfied: pyspark>=3.5.5 in /opt/spark/python (from pyspark-opendic==0.2.6) (3.5.5)\n",
      "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.10/site-packages (from pyspark-opendic==0.2.6) (2.32.3)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.10.6->pyspark-opendic==0.2.6) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.10.6->pyspark-opendic==0.2.6) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.10.6->pyspark-opendic==0.2.6) (4.12.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/site-packages (from pyspark>=3.5.5->pyspark-opendic==0.2.6) (0.10.9.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.3->pyspark-opendic==0.2.6) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.3->pyspark-opendic==0.2.6) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.3->pyspark-opendic==0.2.6) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.3->pyspark-opendic==0.2.6) (3.10)\n",
      "Installing collected packages: pyspark-opendic\n",
      "  Attempting uninstall: pyspark-opendic\n",
      "    Found existing installation: pyspark-opendic 0.2.5\n",
      "    Uninstalling pyspark-opendic-0.2.5:\n",
      "      Successfully uninstalled pyspark-opendic-0.2.5\n",
      "Successfully installed pyspark-opendic-0.2.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark-opendic==0.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8961c31e-19e6-4470-bbae-4611bf76f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/17 15:45:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://0783d2ca4b97:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff8eb9d810>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def read_secret(secret_name):\n",
    "    \"\"\" Get `secret_name` from docker-compose secret store\"\"\"\n",
    "    secret_path = f\"/run/secrets/{secret_name}\"\n",
    "    try:\n",
    "        with open(secret_path, \"r\") as f:\n",
    "            return f.read().strip()  # Remove any trailing newline\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Secret {secret_name} not found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "## DEFINE SENSITIVE VARIABLES\n",
    "POLARIS_CATALOG_NAME = 'polaris'\n",
    "ENGINEER_CLIENT_ID = read_secret(\"engineer_client_id\")\n",
    "ENGINEER_CLIENT_SECRET = read_secret(\"engineer_client_secret\")\n",
    "ADLS_IO=\"org.apache.iceberg.azure.adlsv2.ADLSFileIO\"\n",
    "FILE_IO=\"org.apache.iceberg.io.ResolvingFileIO\"\n",
    "\n",
    "def create_session(client_id, client_secret, scope, fileio_impl):\n",
    "    spark = (SparkSession.builder\n",
    "        .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.0,software.amazon.awssdk:bundle:2.28.17,software.amazon.awssdk:url-connection-client:2.28.17\")\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\")\n",
    "        .config(\"spark.sql.catalog.polaris\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "        .config(\"spark.sql.catalog.polaris.type\", \"rest\")\n",
    "        .config(\"spark.sql.catalog.polaris.warehouse\", POLARIS_CATALOG_NAME)\n",
    "        .config(\"spark.sql.catalog.polaris.uri\", 'http://polaris:8181/api/catalog')\n",
    "        .config(\"spark.sql.catalog.polaris.credential\", f\"{client_id}:{client_secret}\")\n",
    "        .config(\"spark.sql.catalog.polaris.scope\", 'PRINCIPAL_ROLE:ALL')\n",
    "        .config(\"spark.sql.defaultCatalog\", \"polaris\")\n",
    "        .config(\"spark.sql.catalogImplementation\", \"in-memory\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\")\n",
    "        .config(\"spark.sql.catalog.polaris.token-refresh-enabled\", \"true\")\n",
    "        .config(\"spark.sql.catalog.polaris.header.X-Iceberg-Access-Delegation\", 'vended-credentials')\n",
    "        .config(\"spark.sql.catalog.polaris.io-impl\", fileio_impl)\n",
    "        .config(\"spark.history.fs.logDirectory\", \"/home/iceberg/spark-events\")).getOrCreate()\n",
    "        \n",
    "    print(\"Spark Running\")\n",
    "    return spark\n",
    "\n",
    "\n",
    "## Start Spark Session\n",
    "spark = create_session(client_id=ENGINEER_CLIENT_ID, client_secret=ENGINEER_CLIENT_SECRET, scope='PRINCIPAL_ROLE:ALL',fileio_impl=FILE_IO )\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f7adc-e72e-4ae7-b436-4a3f1c7b8e57",
   "metadata": {},
   "source": [
    "## Setting up pyspark-opendic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ccb2cb-8448-4111-b2af-bd3b19b92835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog initialized\n"
     ]
    }
   ],
   "source": [
    "from pyspark_opendic.catalog import OpenDicCatalog\n",
    "\n",
    "# Init polarisx catalog\n",
    "POLARIS_URI= \"http://polaris:8181/api\"\n",
    "catalog = OpenDicCatalog(spark, POLARIS_URI)\n",
    "print(\"Catalog initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d98c61-b213-4bcd-b1ee-216dd8be9d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/17 15:45:28 WARN RESTSessionCatalog: Iceberg REST client is missing the OAuth2 server URI configuration and defaults to http://polaris:8181/api/catalog/v1/oauth/tokens. This automatic fallback will be removed in a future Iceberg release.It is recommended to configure the OAuth2 endpoint using the 'oauth2-server-uri' property to be prepared. This warning will disappear if the OAuth2 endpoint is explicitly configured. See https://github.com/apache/iceberg/issues/10537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|   SYSTEM|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catalog.sql(\"Show namespaces\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68bd999-9f33-4c28-8568-dec8b3f6dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "use SYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e55351-16ef-4820-9f74-2233a3dc30a7",
   "metadata": {},
   "source": [
    "### Define the schema for a andfunc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99808c3e-7fef-42f6-9a1e-4e44b798c69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Object defined successfully',\n",
       " 'response': {'function_v2': '{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"uname\",\"required\":true,\"type\":\"string\"},{\"id\":2,\"name\":\"args\",\"required\":false,\"type\":{\"type\":\"map\",\"key-id\":14,\"key\":\"string\",\"value-id\":15,\"value\":\"string\",\"value-required\":true}},{\"id\":3,\"name\":\"return_type\",\"required\":false,\"type\":\"string\"},{\"id\":4,\"name\":\"def\",\"required\":false,\"type\":\"string\"},{\"id\":5,\"name\":\"signature\",\"required\":false,\"type\":\"string\"},{\"id\":6,\"name\":\"runtime\",\"required\":false,\"type\":\"string\"},{\"id\":7,\"name\":\"language\",\"required\":false,\"type\":\"string\"},{\"id\":8,\"name\":\"comment\",\"required\":false,\"type\":\"string\"},{\"id\":9,\"name\":\"packages\",\"required\":false,\"type\":{\"type\":\"list\",\"element-id\":16,\"element\":\"string\",\"element-required\":true}},{\"id\":10,\"name\":\"client_version\",\"required\":false,\"type\":\"int\"},{\"id\":11,\"name\":\"created_time\",\"required\":false,\"type\":\"string\"},{\"id\":12,\"name\":\"last_updated_time\",\"required\":false,\"type\":\"string\"},{\"id\":13,\"name\":\"entity_version\",\"required\":false,\"type\":\"int\"}]}'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    DEFINE OPEN function_v2\n",
    "    props {\n",
    "        \"args\": \"MAP\",\n",
    "        \"language\": \"STRING\",\n",
    "        \"def\": \"string\",\n",
    "        \"comment\": \"string\",\n",
    "        \"packages\": \"list\",\n",
    "        \"runtime\": \"string\",\n",
    "        \"client_version\": \"int\",\n",
    "        \"signature\": \"STRING\",\n",
    "        \"return_type\": \"STRING\"\n",
    "    }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a117eb1-0929-4e30-9dea-c6980411f991",
   "metadata": {},
   "source": [
    "### Create a new andfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b83c05-2e49-449c-9fc3-f644acf682c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Object created successfully',\n",
       " 'response': {'function_v2 foo': 'Record(foo, {arg1=int, arg2=int}, int, def foo(arg1, arg2):\\n        return arg1 + arg2, foo(arg1 str, arg2 int), 3.12, python, test fun, [numpy, pandas], 1, 2025-04-17T15:46:44.073747095Z, 2025-04-17T15:46:44.073763553Z, 1)'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    " \"\"\"\n",
    " CREATE OPEN function_v2 foo\n",
    "    props {\n",
    "            \"args\": {\n",
    "                \"arg1\": \"int\", \n",
    "                \"arg2\": \"int\"\n",
    "                },\n",
    "            \"language\": \"python\",\n",
    "            \"def\": \"def foo(arg1, arg2):\\\\n        return arg1 + arg2\",\n",
    "            \"packages\" : [\"numpy\", \"pandas\"],\n",
    "            \"comment\": \"test fun\",\n",
    "            \"runtime\": \"3.12\",\n",
    "            \"client_version\": 1,\n",
    "            \"return_type\": \"int\",\n",
    "            \"signature\": \"foo(arg1 str, arg2 int)\"\n",
    "        }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4ce21-1ded-4e92-8b3a-18f3d2264aa7",
   "metadata": {},
   "source": [
    "### Create Mapping to snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3023dc59-10d0-42fe-8fa8-c9662c9b2078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Mapping added successfully',\n",
       " 'response': {'Createdfunction_v2-->snowflakemapping': 'Record(function_v2, snowflake, \"CREATE OR ALTER <type> <name>(<args>)\\n            RETURNS <return_type>\\n            LANGUAGE <language>\\n            RUNTIME = <runtime>\\n            HANDLER = \\'<name>\\'\\n            AS \\n            $$\\n            <def>\\n            $$\",, {args=Record(map, <key> <value>, , ), packages=Record(list, \\'<item>\\', , )}, 2025-04-17T15:46:58.357591796Z, 2025-04-17T15:46:58.357608421Z, 1)'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    ADD OPEN MAPPING function_v2 PLATFORM snowflake\n",
    "    SYNTAX {\n",
    "        \"CREATE OR ALTER <type> <name>(<args>)\n",
    "            RETURNS <return_type>\n",
    "            LANGUAGE <language>\n",
    "            RUNTIME = <runtime>\n",
    "            HANDLER = '<name>'\n",
    "            AS \n",
    "            $$\n",
    "            <def>\n",
    "            $$\",\n",
    "    }\n",
    "    PROPS {\n",
    "        \"args\": {\n",
    "                \"propType\": \"map\",\n",
    "                \"format\": \"<key> <value>\",\n",
    "                \"delimiter\": \", \"\n",
    "            },\n",
    "        \"packages\": {\"propType\": \"list\", \"format\": \"'<item>'\", \"delimiter\": \", \"}\n",
    "    }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b019448-2b04-4063-a812-bb598122ef04",
   "metadata": {},
   "source": [
    "### List objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b13db8f-0e7c-4e0b-8b88-ba092fe91530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Object types retrieved successfully',\n",
       " 'response': {'function_v2': '{\"type\":\"struct\",\"schema-id\":0,\"fields\":[{\"id\":1,\"name\":\"uname\",\"required\":true,\"type\":\"string\"},{\"id\":2,\"name\":\"args\",\"required\":false,\"type\":{\"type\":\"map\",\"key-id\":14,\"key\":\"string\",\"value-id\":15,\"value\":\"string\",\"value-required\":true}},{\"id\":3,\"name\":\"return_type\",\"required\":false,\"type\":\"string\"},{\"id\":4,\"name\":\"def\",\"required\":false,\"type\":\"string\"},{\"id\":5,\"name\":\"signature\",\"required\":false,\"type\":\"string\"},{\"id\":6,\"name\":\"runtime\",\"required\":false,\"type\":\"string\"},{\"id\":7,\"name\":\"language\",\"required\":false,\"type\":\"string\"},{\"id\":8,\"name\":\"comment\",\"required\":false,\"type\":\"string\"},{\"id\":9,\"name\":\"packages\",\"required\":false,\"type\":{\"type\":\"list\",\"element-id\":16,\"element\":\"string\",\"element-required\":true}},{\"id\":10,\"name\":\"client_version\",\"required\":false,\"type\":\"int\"},{\"id\":11,\"name\":\"created_time\",\"required\":false,\"type\":\"string\"},{\"id\":12,\"name\":\"last_updated_time\",\"required\":false,\"type\":\"string\"},{\"id\":13,\"name\":\"entity_version\",\"required\":false,\"type\":\"int\"}]}'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN TYPES\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d6a8bb-2989-4873-a8b4-e78416aea85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Objects retrieved successfully',\n",
       " 'response': [{'type': 'function_v2',\n",
       "   'name': 'foo',\n",
       "   'props': {'args': {'arg1': 'int', 'arg2': 'int'},\n",
       "    'return_type': 'int',\n",
       "    'def': 'def foo(arg1, arg2):\\n        return arg1 + arg2',\n",
       "    'signature': 'foo(arg1 str, arg2 int)',\n",
       "    'runtime': '3.12',\n",
       "    'language': 'python',\n",
       "    'comment': 'test fun',\n",
       "    'packages': ['numpy', 'pandas'],\n",
       "    'client_version': 1},\n",
       "   'createTimestamp': 1744904804,\n",
       "   'lastUpdateTimestamp': 1744904804,\n",
       "   'entityVersion': 1}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN function_v2\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08a0829-e1bc-40a4-b2e9-583369bc2785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Mapping retrieved successfully',\n",
       " 'response': {'typeName': 'function_v2',\n",
       "  'platformName': 'snowflake',\n",
       "  'syntax': '\"CREATE OR ALTER <type> <name>(<args>)\\n            RETURNS <return_type>\\n            LANGUAGE <language>\\n            RUNTIME = <runtime>\\n            HANDLER = \\'<name>\\'\\n            AS \\n            $$\\n            <def>\\n            $$\",',\n",
       "  'objectDumpMap': {'args': {'propType': 'map',\n",
       "    'format': '<key> <value>',\n",
       "    'delimiter': ', '},\n",
       "   'packages': {'propType': 'list', 'format': \"'<item>'\", 'delimiter': ', '}},\n",
       "  'createdTimestamp': '2025-04-17T15:46:58.357591Z',\n",
       "  'lastUpdatedTimestamp': '2025-04-17T15:46:58.357608Z',\n",
       "  'version': 1}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show mapping for <object> to <platform>. Example: [Platform_mapping(function_v2 -> snowflake)]\n",
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN MAPPING function_v2 PLATFORM snowflake\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "465f2f0d-4042-4304-92e7-9b08b1154757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Platforms retrieved successfully',\n",
       " 'response': [{'typeName': 'function_v2',\n",
       "   'platformName': 'snowflake',\n",
       "   'syntax': '\"CREATE OR ALTER <type> <name>(<args>)\\n            RETURNS <return_type>\\n            LANGUAGE <language>\\n            RUNTIME = <runtime>\\n            HANDLER = \\'<name>\\'\\n            AS \\n            $$\\n            <def>\\n            $$\",',\n",
       "   'objectDumpMap': {'args': {'propType': 'map',\n",
       "     'format': '<key> <value>',\n",
       "     'delimiter': ', '},\n",
       "    'packages': {'propType': 'list', 'format': \"'<item>'\", 'delimiter': ', '}},\n",
       "   'createdTimestamp': '2025-04-17T15:46:58.357591Z',\n",
       "   'lastUpdatedTimestamp': '2025-04-17T15:46:58.357608Z',\n",
       "   'version': 1}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all mappings from <object>. Example: [snowflake,spark]\n",
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN PLATFORMS FOR function_v2\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d38ccc6c-fac8-4d6c-a9d6-a556d5a91037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Platforms retrieved successfully',\n",
       " 'response': [{'platformName': 'snowflake',\n",
       "   'platformMappings': [{'typeName': 'function_v2',\n",
       "     'platformName': 'snowflake',\n",
       "     'syntax': '\"CREATE OR ALTER <type> <name>(<args>)\\n            RETURNS <return_type>\\n            LANGUAGE <language>\\n            RUNTIME = <runtime>\\n            HANDLER = \\'<name>\\'\\n            AS \\n            $$\\n            <def>\\n            $$\",',\n",
       "     'objectDumpMap': {'args': {'propType': 'map',\n",
       "       'format': '<key> <value>',\n",
       "       'delimiter': ', '},\n",
       "      'packages': {'propType': 'list',\n",
       "       'format': \"'<item>'\",\n",
       "       'delimiter': ', '}},\n",
       "     'createdTimestamp': '2025-04-17T15:46:58.357591Z',\n",
       "     'lastUpdatedTimestamp': '2025-04-17T15:46:58.357608Z',\n",
       "     'version': 1}]}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN PLATFORMS\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e9d02df-c4f4-46f4-b707-99d3d2869d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Mappings for platform retrieved successfully',\n",
       " 'response': ['Record(function_v2, snowflake, \"CREATE OR ALTER <type> <name>(<args>)\\n            RETURNS <return_type>\\n            LANGUAGE <language>\\n            RUNTIME = <runtime>\\n            HANDLER = \\'<name>\\'\\n            AS \\n            $$\\n            <def>\\n            $$\",, {args=Record(map, <key> <value>, , ), packages=Record(list, \\'<item>\\', , )}, 2025-04-17T15:46:58.357591Z, 2025-04-17T15:46:58.357608Z, 1)']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SHOW OPEN MAPPINGS FOR snowflake\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2991f5-6099-4bc0-9e64-dda501c6104f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43;03m    SYNC OPEN function_v2 for snowflake\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark_opendic/catalog.py:280\u001b[0m, in \u001b[0;36mOpenDicCatalog.sql\u001b[0;34m(self, sqlText)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP Error\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexception message\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(e)}\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m define_match:\n\u001b[1;32m    283\u001b[0m     udoType \u001b[38;5;241m=\u001b[39m define_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mudoType\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark_opendic/catalog.py:371\u001b[0m, in \u001b[0;36mOpenDicCatalog.dump_handler\u001b[0;34m(self, json_dump)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump_handler\u001b[39m(\u001b[38;5;28mself\u001b[39m, json_dump : \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]):\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    Extracts SQL statements from the Polaris response and executes them using Spark.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        list: A list of results from executing the SQL statements.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     statements : \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mjson_dump\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatements\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])  \u001b[38;5;66;03m# Extract the list of SQL statements\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m statements:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo statements found in response\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    SYNC OPEN function_v2 for snowflake\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13475c-abcc-4bed-96d5-0d9044aee319",
   "metadata": {},
   "source": [
    "### Drop andfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62ba6692-c3a3-45e8-b1a6-a7d33697a990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 'Object dropped successfully',\n",
       " 'response': {'Deleted all objects of type': 'function_v2'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    DROP OPEN function_v2\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159960df-32ec-4d43-a16a-86e32780e4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'HTTP Error',\n",
       " 'exception message': '404 Client Error: Not Found for url: http://polaris:8181/api/opendic/v1/platforms/snowflake'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.sql(\n",
    "    \"\"\"\n",
    "    DROP OPEN MAPPINGS for snowflake\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f67035-aa7b-4eab-8ba0-7e7132c68106",
   "metadata": {},
   "source": [
    "### Visualize opendic tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66730eb2-aa42-42b5-8f15-f6fb6c3908d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "show tables in SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1708a-3517-4c09-aaad-f51d08929cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from andfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb219f-304b-47c3-91b1-6bf220580183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESCRIBE EXTENDED SYSTEM.andfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a9f41",
   "metadata": {},
   "source": [
    "## Load One Month of NYC Taxi/Limousine Trip Data\n",
    "\n",
    "For this notebook, we will use the New York City Taxi and Limousine Commision Trip Record Data that's available on the AWS Open Data Registry. This contains data of trips taken by taxis and for-hire vehicles in New York City. We'll save this into an iceberg table called `taxis`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bee98",
   "metadata": {},
   "source": [
    "To be able to rerun the notebook several times, let's drop the table if it exists to start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930682ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/home/iceberg/data/yellow_tripdata_2021-04.parquet\")\n",
    "df.write.saveAsTable(\"nyc.taxis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DESCRIBE EXTENDED nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf99fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) as cnt\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd2c03",
   "metadata": {},
   "source": [
    "## Schema Evolution\n",
    "\n",
    "Adding, dropping, renaming, or altering columns is easy and safe in Iceberg. In this example, we'll rename `fare_amount` to `fare` and `trip_distance` to `distance`. We'll also add a float column `fare_per_distance_unit` immediately after `distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis RENAME COLUMN fare_amount TO fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794de3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis RENAME COLUMN trip_distance TO distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis ALTER COLUMN distance COMMENT 'The elapsed trip distance in miles reported by the taximeter.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis ALTER COLUMN distance TYPE double;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis ALTER COLUMN distance AFTER fare;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis\n",
    "ADD COLUMN fare_per_distance_unit float AFTER distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416b498",
   "metadata": {},
   "source": [
    "Let's update the new `fare_per_distance_unit` to equal `fare` divided by `distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18771ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "UPDATE nyc.taxis\n",
    "SET fare_per_distance_unit = fare/distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c72ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "VendorID\n",
    ",tpep_pickup_datetime\n",
    ",tpep_dropoff_datetime\n",
    ",fare\n",
    ",distance\n",
    ",fare_per_distance_unit\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37582e02",
   "metadata": {},
   "source": [
    "## Expressive SQL for Row Level Changes\n",
    "With Iceberg tables, `DELETE` queries can be used to perform row-level deletes. This is as simple as providing the table name and a `WHERE` predicate. If the filter matches an entire partition of the table, Iceberg will intelligently perform a metadata-only operation where it simply deletes the metadata for that partition.\n",
    "\n",
    "Let's perform a row-level delete for all rows that have a `fare_per_distance_unit` greater than 4 or a `distance` greater than 2. This should leave us with relatively short trips that have a relatively high fare per distance traveled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded820f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DELETE FROM nyc.taxis\n",
    "WHERE fare_per_distance_unit > 4.0 OR distance > 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faef3712",
   "metadata": {},
   "source": [
    "There are some fares that have a `null` for `fare_per_distance_unit` due to the distance being `0`. Let's remove those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b69265",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DELETE FROM nyc.taxis\n",
    "WHERE fare_per_distance_unit is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "VendorID\n",
    ",tpep_pickup_datetime\n",
    ",tpep_dropoff_datetime\n",
    ",fare\n",
    ",distance\n",
    ",fare_per_distance_unit\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) as cnt\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b157e5",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    "\n",
    "A table’s partitioning can be updated in place and applied only to newly written data. Query plans are then split, using the old partition scheme for data written before the partition scheme was changed, and using the new partition scheme for data written after. People querying the table don’t even have to be aware of this split. Simple predicates in WHERE clauses are automatically converted to partition filters that prune out files with no matches. This is what’s referred to in Iceberg as *Hidden Partitioning*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis\n",
    "ADD PARTITION FIELD VendorID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce6bb4",
   "metadata": {},
   "source": [
    "## Metadata Tables\n",
    "\n",
    "Iceberg tables contain very rich metadata that can be easily queried. For example, you can retrieve the manifest list for any snapshot, simply by querying the table's `snapshots` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fade1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT snapshot_id, manifest_list\n",
    "FROM nyc.taxis.snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64887133",
   "metadata": {},
   "source": [
    "The `files` table contains loads of information on data files, including column level statistics such as null counts, lower bounds, and upper bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb712f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT file_path, file_format, record_count, null_value_counts, lower_bounds, upper_bounds\n",
    "FROM nyc.taxis.files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65deb074",
   "metadata": {},
   "source": [
    "## Time Travel\n",
    "\n",
    "The history table lists all snapshots and which parent snapshot they derive from. The `is_current_ancestor` flag let's you know if a snapshot is part of the linear history of the current snapshot of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab64f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM nyc.taxis.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47129d69",
   "metadata": {},
   "source": [
    "You can time-travel by altering the `current-snapshot-id` property of the table to reference any snapshot in the table's history. Let's revert the table to it's original state by traveling to the very first snapshot ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c360238",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --var df\n",
    "\n",
    "SELECT *\n",
    "FROM nyc.taxis.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df43d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_snapshot = df.head().snapshot_id\n",
    "spark.sql(f\"CALL system.rollback_to_snapshot('nyc.taxis', {original_snapshot})\")\n",
    "original_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "VendorID\n",
    ",tpep_pickup_datetime\n",
    ",tpep_dropoff_datetime\n",
    ",fare\n",
    ",distance\n",
    ",fare_per_distance_unit\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b71c76",
   "metadata": {},
   "source": [
    "Another look at the history table shows that the original state of the table has been added as a new entry\n",
    "with the original snapshot ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b801d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM nyc.taxis.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85667efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) as cnt\n",
    "FROM nyc.taxis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
